---
title: "Pandemic Deaths"
---


```{r}
# 
#| eval: false
# Import the required modules
# import requests
# import json
# from bs4 import BeautifulSoup

# # Define the URL of the Wikipedia page
# url = "https://en.wikipedia.org/wiki/List_of_deaths_due_to_COVID-19"

# # Make a GET request to fetch the raw HTML content
# html_content = requests.get(url).text

# # Parse the HTML content using BeautifulSoup
# soup = BeautifulSoup(html_content, "lxml")

# # Find the table element that contains the data
# table = soup.find("table", attrs={"class": "wikitable sortable"})

# # Get all the rows of the table
# rows = table.find_all("tr")

# # Create an empty list to store the data
# data = []

# # Loop through each row and extract the relevant information
# for row in rows:
#   # Get all the cells of the row
#   cells = row.find_all("td")
#   # If there are cells, then it is not a header row
#   if cells:
#     # Get the name, description and age at death from each cell
#     name = cells[0].text.strip()
#     description = cells[1].text.strip()
#     age_at_death = int(cells[2].text.strip())
#     # Create a dictionary with these values
#     record = {"name": name, "description": description, "age_at_death": age_at_death}
#     # Append it to the data list
#     data.append(record)

# # Convert the data list to a JSON string using json.dumps()
# json_data = json.dumps(data)

# Print or save or use json_data as you wish
```

![After the pandemic](https://storage.googleapis.com/boom-ai-images/results/ftq07WtWPhYnnZt6jyo7/00005.jpg)

